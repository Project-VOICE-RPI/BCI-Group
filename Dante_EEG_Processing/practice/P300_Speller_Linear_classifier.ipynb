{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://www.kaggle.com/code/pochenliu/linear-classifiers-xdawn-100-letter-accuracy",
   "id": "4916a8981d95efcd"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T21:26:46.288550Z",
     "start_time": "2024-11-22T21:26:44.040897Z"
    }
   },
   "source": [
    "from tables import current_dir\n",
    "!pip install mat4py\n",
    "!pip install kagglehub"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mat4py in /home/dante/miniconda3/envs/mne/lib/python3.12/site-packages (0.6.0)\r\n",
      "Requirement already satisfied: kagglehub in /home/dante/miniconda3/envs/mne/lib/python3.12/site-packages (0.3.4)\r\n",
      "Requirement already satisfied: packaging in /home/dante/miniconda3/envs/mne/lib/python3.12/site-packages (from kagglehub) (24.1)\r\n",
      "Requirement already satisfied: requests in /home/dante/miniconda3/envs/mne/lib/python3.12/site-packages (from kagglehub) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /home/dante/miniconda3/envs/mne/lib/python3.12/site-packages (from kagglehub) (4.66.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dante/miniconda3/envs/mne/lib/python3.12/site-packages (from requests->kagglehub) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dante/miniconda3/envs/mne/lib/python3.12/site-packages (from requests->kagglehub) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dante/miniconda3/envs/mne/lib/python3.12/site-packages (from requests->kagglehub) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dante/miniconda3/envs/mne/lib/python3.12/site-packages (from requests->kagglehub) (2024.8.30)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:27:07.558076Z",
     "start_time": "2024-11-22T21:26:46.318714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "path = kagglehub.dataset_download(\"rramele/p300samplingdataset\")\n",
    "loc = \"../p300samplingdataset/\"\n",
    "shutil.move(path, loc)\n",
    "print(\"Path to dataset files: \", path)"
   ],
   "id": "aa7d16988f23f71f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/rramele/p300samplingdataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308M/308M [00:19<00:00, 16.6MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files:  /home/dante/.cache/kagglehub/datasets/rramele/p300samplingdataset/versions/1\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:27:08.202791Z",
     "start_time": "2024-11-22T21:27:07.580016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from mat4py import loadmat\n",
    "import time\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import welch, freqz, butter, filtfilt\n",
    "from sklearn.model_selection import cross_val_predict, TimeSeriesSplit\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import  GaussianNB, MultinomialNB, BernoulliNB, CategoricalNB, ComplementNB\n",
    "\n",
    "from mne import (io, compute_raw_covariance, read_events, pick_types, Epochs)\n",
    "from mne.preprocessing import Xdawn\n",
    "from mne.viz import plot_epochs_image\n",
    "import mne\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import os"
   ],
   "id": "62ae1e902dd98f22",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:27:08.216150Z",
     "start_time": "2024-11-22T21:27:08.211113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folder = '../p300samplingdataset/*.mat'\n",
    "files = glob.glob(folder)\n",
    "print(files)\n",
    "print(len(files))\n",
    "\n",
    "channels = ['Fz', 'Cz', 'P3', 'Pz', 'P4', 'P07', 'P08', 'Oz']"
   ],
   "id": "88488901a8584362",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../p300samplingdataset/P300S02.mat', '../p300samplingdataset/P300S04.mat', '../p300samplingdataset/P300S06.mat', '../p300samplingdataset/P300S08.mat', '../p300samplingdataset/P300S07.mat', '../p300samplingdataset/P300S01.mat', '../p300samplingdataset/P300S05.mat', '../p300samplingdataset/P300S03.mat']\n",
      "8\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:27:08.329366Z",
     "start_time": "2024-11-22T21:27:08.325570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(file):\n",
    "    raw_data = loadmat(file)\n",
    "    useful_data = raw_data['data'].copy()\n",
    "    X = useful_data['X']\n",
    "    Y = useful_data['y']\n",
    "    T = useful_data['trial']\n",
    "    F = useful_data['flash']\n",
    "    \n",
    "    return X, Y, T, F"
   ],
   "id": "1d4c820d3708f857",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:27:08.387155Z",
     "start_time": "2024-11-22T21:27:08.382050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5): \n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ],
   "id": "35185403bae2519",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:27:08.500620Z",
     "start_time": "2024-11-22T21:27:08.440215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Cut the data into trials\n",
    "def prepare_data(X, Y, flash, start, stop, filter_boo):\n",
    "    X = np.array(X)\n",
    "\n",
    "    if filter_boo:\n",
    "        X = butter_bandpass_filter(X.T, low, high, fs).T\n",
    "\n",
    "    start_samples = int(start*fs)\n",
    "    stop_samples = int(stop*fs)\n",
    "\n",
    "    X_samples = np.zeros((len(flash)-120, int(stop_samples-start_samples), 8))\n",
    "\n",
    "    for i in range(len(flash)-120):\n",
    "        event = flash[i][0]\n",
    "        X_samples[i, :, :] = X[event+start_samples:event+stop_samples :]\n",
    "    label     = [i[3] - 1 for i in flash]\n",
    "\n",
    "    LIMIT = 4080 #the last trial is incomplete\n",
    "    y = np.array(label[:LIMIT])\n",
    "    X_samples = X_samples.reshape(X_samples.shape[0], X_samples.shape[1] * X_samples.shape[2])\n",
    "\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "    X_under, y_under = undersample.fit_resample(X_samples, y)\n",
    "\n",
    "    #     print(X_under.shape, y_under.shape)\n",
    "    #     print(sum(y_under))\n",
    "\n",
    "    return X_under, y_under\n",
    "\n",
    "\n",
    "def prepare_data_nonUS(X, Y, flash, start, stop):\n",
    "    X = np.array(X)\n",
    "\n",
    "    start_samples = int(start*fs)\n",
    "    stop_samples = int(stop*fs)\n",
    "\n",
    "    X_samples = np.zeros((len(flash)-120, int(stop_samples-start_samples), 8))\n",
    "\n",
    "    for i in range(len(flash)-120):\n",
    "        event = flash[i][0] # should have 4080 flash events\n",
    "        X_samples[i, :, :] = X[event+start_samples:event+stop_samples :] # should generate 4080 rows of 8 x 250 samples\n",
    "    label     = [i[3] - 1 for i in flash] # hit = 1 nohit = 0, getting 4200 of them\n",
    "\n",
    "    LIMIT = 4080 #the last trial is incomplete\n",
    "    y = np.array(label[:LIMIT]) # taking the first 4080 out of these\n",
    "    X_samples = X_samples.reshape(X_samples.shape[0], X_samples.shape[1] * X_samples.shape[2]) # reshape into 4080 rows of 8x250 = 2000 array\n",
    "\n",
    "    # simply commented out\n",
    "    #    undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "    #    X_under, y_under = undersample.fit_resample(X_samples, y) # so retain in undersamples: equal numbers of hits & no hits\n",
    "\n",
    "    #     print(X_under.shape, y_under.shape)\n",
    "    #     print(sum(y_under))\n",
    "\n",
    "    return X_samples, y"
   ],
   "id": "6adeec47439d223f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:28:02.995185Z",
     "start_time": "2024-11-22T21:27:59.471515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "appX = []\n",
    "appy = []\n",
    "\n",
    "start = 0\n",
    "stop = 1\n",
    "fs = 250\n",
    "\n",
    "for i in range(len(files)-7):\n",
    "    file = files[i]\n",
    "    X, Y, Trials, Flash = load_data(file)\n",
    "    X_clean, y_clean = prepare_data(X, Y, Flash, start, stop, False)\n",
    "    appX.append(X_clean)\n",
    "    appy.append(np.array(y_clean))"
   ],
   "id": "59db81244c8f3396",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "print(appX)",
   "id": "667bfe8aad584380",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
